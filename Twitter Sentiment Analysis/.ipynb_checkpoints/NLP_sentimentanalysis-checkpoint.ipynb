{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman Sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damn the person who stolde my wallet !!!!!  Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars Pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>@Calumfan1 is it in any way related to photosh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>@Swiz_NZ really? wow thats crap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>At the 2010 lexus HS250h press event.  Again, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>@karmicunderpath ooooh now there's a nice thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>@mariap91 i'd usually ask you about the sun an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitts  sentiment\n",
       "0           @robbiebronniman Sounds like a great night.           1\n",
       "1      Damn the person who stolde my wallet !!!!!  Ma...          1\n",
       "2      Greetings from the piano bench  (photo) http:/...          1\n",
       "3      @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4      @kissthestars Pretty pretty pretty please, pak...          0\n",
       "...                                                  ...        ...\n",
       "29995  @Calumfan1 is it in any way related to photosh...          0\n",
       "29996                   @Swiz_NZ really? wow thats crap           0\n",
       "29997  At the 2010 lexus HS250h press event.  Again, ...          0\n",
       "29998  @karmicunderpath ooooh now there's a nice thou...          1\n",
       "29999  @mariap91 i'd usually ask you about the sun an...          1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/twitter-data/master/twitt30k.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitts       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15000\n",
       "1    15000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(df):\n",
    "    X=df['twitts']\n",
    "    y=df['sentiment']\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(df['twitts'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "                            \n",
    "    print('shape of X: ', X.shape)                        \n",
    "    \n",
    "    #Train Model\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print()\n",
    "    print('Printing Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return tfidf, clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 40854)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      3000\n",
      "           1       0.74      0.75      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n",
      "CPU times: user 542 ms, sys: 13.1 ms, total: 556 ms\n",
      "Wall time: 553 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf, clf = run_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['i am really happy. thanks a lot for coming with me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Retraining SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_andy as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'get_avg_wordlength',\n",
       " 'get_characcounts',\n",
       " 'get_cont_exp',\n",
       " 'get_digit_counts',\n",
       " 'get_emails',\n",
       " 'get_hashtag_counts',\n",
       " 'get_mentions_counts',\n",
       " 'get_stopwords_counts',\n",
       " 'get_uppercase_counts',\n",
       " 'get_urls',\n",
       " 'get_value_counts',\n",
       " 'get_wordcount',\n",
       " 'make_to_base',\n",
       " 'remove_accented_chars',\n",
       " 'remove_common_words',\n",
       " 'remove_emails',\n",
       " 'remove_html_tags',\n",
       " 'remove_rarewords',\n",
       " 'remove_rt',\n",
       " 'remove_special_chars',\n",
       " 'remove_stopwords',\n",
       " 'remove_urls',\n",
       " 'spelling_correction',\n",
       " 'utils']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply lower and Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x: pp.get_cont_exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damn the person who stolde my wallet !!!!!  ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              twitts  sentiment\n",
       "0       @robbiebronniman sounds like a great night.           1\n",
       "1  damn the person who stolde my wallet !!!!!  ma...          1\n",
       "2  greetings from the piano bench  (photo) http:/...          1\n",
       "3  @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4  @kissthestars pretty pretty pretty please, pak...          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 40846)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      3000\n",
      "           1       0.75      0.76      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(), LinearSVC())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_svm(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE EMAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_emails(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_urls(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_rt(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_html_tags(x))\n",
    "df['twitts'] = df['twitts'].apply(lambda x: pp.remove_special_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robbiebronniman sounds like a great night</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damn the person who stolde my wallet may karma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greetings from the piano bench photo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drewryanscott i love it i love you haha forget...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kissthestars pretty pretty pretty please pakid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>calumfan1 is it in any way related to photoshop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>swiz_nz really wow thats crap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>at the 2010 lexus hs250h press event again can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>karmicunderpath ooooh now there is a nice thought</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>mariap91 i would usually ask you about the sun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  twitts  sentiment\n",
       "0              robbiebronniman sounds like a great night          1\n",
       "1      damn the person who stolde my wallet may karma...          1\n",
       "2                   greetings from the piano bench photo          1\n",
       "3      drewryanscott i love it i love you haha forget...          1\n",
       "4      kissthestars pretty pretty pretty please pakid...          0\n",
       "...                                                  ...        ...\n",
       "29995    calumfan1 is it in any way related to photoshop          0\n",
       "29996                      swiz_nz really wow thats crap          0\n",
       "29997  at the 2010 lexus hs250h press event again can...          0\n",
       "29998  karmicunderpath ooooh now there is a nice thought          1\n",
       "29999  mariap91 i would usually ask you about the sun...          1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 42983)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      3000\n",
      "           1       0.74      0.75      0.75      3000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n",
      "CPU times: user 545 ms, sys: 4.67 ms, total: 550 ms\n",
      "Wall time: 548 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf, clf = run_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (30000, 5000)\n",
      "\n",
      "Printing Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      3000\n",
      "           1       0.77      0.75      0.76      3000\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.76      0.76      0.76      6000\n",
      "weighted avg       0.76      0.76      0.76      6000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(max_features=5000, ngram_range=(1, 2), norm='l1'),\n",
       " LinearSVC())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_svm(df):\n",
    "    X = df['twitts']\n",
    "    y = df['sentiment']\n",
    "\n",
    "    tfidf = TfidfVectorizer(norm = 'l1', ngram_range=(1,2), analyzer='word', max_features=5000)\n",
    "    X = tfidf.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "\n",
    "    print('shape of X: ', X.shape)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print()\n",
    "    print('Printing Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return tfidf, clf\n",
    "\n",
    "run_svm(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING AND LOADING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('clf.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clf\n",
    "del tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('clf.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'i47xjSBBe07R8zGauaQbl7oBA'\n",
    "consumer_secret = 'sZoeCAoTO5zrHi270dBhhQhL203I6kQUjfKSRABrvQTxeSH9Zj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = '232661448-abXPKetKXDIWIU7RHZwstkNxw7vlONjKgjhDBEM7'\n",
    "access_token_secret = 'mxJbEvny2kv3UsP6DkwSQAG11VlYnZJy3O2s0ywdYOl53'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @alisher_ai: Last 1000 members to reach 10k members ðŸ¥³ Thank you for joining @__MLT__ and looking forward to learning and contributing toâ€¦\n",
      "RT @into_AI: How can radiologists benefit from AI in 2021? - May 12, 2021 -- So let's say y https://t.co/X9vmDnKQpG #ai #intoAInews\n",
      "RT @subex: Read our next blog to know the challenges faced by CIOs and how these challenges can be addressed by leveraging emerging technolâ€¦\n",
      "RT @Rohit_kasture: For the development and testing of #autonomous vehicles, the #Cloud is the environment of choice. However, rapidly expanâ€¦\n",
      "RT @Samu3lR0y: Pico4ML Brings Machine Learning To the Raspberry Pi Pico - Tom's Hardware\n",
      "\n",
      "Read more here: https://t.co/fX08wxHVyr\n",
      "\n",
      "#Artificâ€¦\n",
      "RT @Clement_MENGUE: My Disruptive Tech Deal Daily! https://t.co/Vw7uyokFik Thanks to @grjenkin #artificialintelligence #machinelearning\n",
      "RT @HarbRimah: #infographic Investing in Core Cybersecurity Technology is a must \n",
      "\n",
      "#AI #data #CyberSecurity #technology #tech #cybercrime #â€¦\n",
      "RT @datos_digital: Cisco Acquires Socio as Event Tech Deals Now in Full Swing : #analytics #googleads #facebookads https://t.co/c4XkgiC0N9\n",
      "RT @_AskSid: Welcome to the world of SID, our digital #shopping assistant, and the core of how we deliver extraordinary shopping #experiencâ€¦\n",
      "RT @RichardEudes: Artificial Intelligence And The Future Of Humans https://t.co/cSLGaJpHl0 #artificialintelligence, #businessanalytics #ba,â€¦\n",
      "RT @PrimeClasses_: Data Science Glossary : Interpretability ?\n",
      "\n",
      "#MachineLearning #Artificialintelligence #AI #DataScience #Python #ML #Deeplâ€¦\n",
      "RT @Mlearning_ai: Exploratory Data Analysis: A Beginnerâ€™s Guide \n",
      "// by yeshwanth kumar maringanti https://t.co/0KJYaTWpxE\n",
      "#machinelearningâ€¦\n",
      "RT @FabienBrodie: Natural Language Processing and Machine Learning for Identifying Incident Stroke From Electronic Health Records: Algorithâ€¦\n",
      "RT @FabienBrodie: Researchers enhance quantum machine learning algorithms - https://t.co/jozzEXEQam\n",
      "\n",
      "Read more here: https://t.co/U1H94aZ9Fâ€¦\n",
      "RT @BenjaminP3ters: Voice your opinion Artificial Intelligence: Reinforcing discrimination - The Parliament Magazine\n",
      "\n",
      "Read more here: httpsâ€¦\n",
      "RT @BenjaminP3ters: Kazuo Ishiguro writes of artificial intelligence and human hearts in â€˜Klara and the Sunâ€™ - Tampa Bay Times\n",
      "\n",
      "Read more hâ€¦\n",
      "RT @IainLJBrown: If Levity creates an artificial intelligence DIY boom, weâ€™ll all be laughing - https://t.co/Q8vMc8Jdxw\n",
      "\n",
      "Read more here: htâ€¦\n",
      "RT @InCallify: #Artificialintelligence could be adding to the bias at your company.\n",
      "\n",
      "Read here to know why- https://t.co/DJNqMpJsJw\n",
      "\n",
      "#humanâ€¦\n",
      "RT @mbarada: Our Headlines for Today ðŸ”¥ðŸ’¥ on https://t.co/YKP8regRx2\n",
      "ðŸ”ƒStay updated with the latest News About #Technology, #ERP, #CRM, #Digitâ€¦\n",
      "RT @native_stack: Machine Learning for Physicists (Lecture 5): Principal Component Analysis, t-SNE, Adam etc., ... #machinelearning ðŸ‘ˆ httpsâ€¦\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRACKING KEYWORDS ON TWITTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_keyword = ['usa','china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "    def on_data(self, data):\n",
    "        raw_twitt = json.loads(data)\n",
    "        try:\n",
    "            print(raw_twitt['text'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_error disconnects the stream\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStream.filter(track=track_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "nlp_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
